{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92188d8",
   "metadata": {},
   "source": [
    "### Data Cleaning  \n",
    "將語句資料經過處理，將不需要(不影響內容)的部分去除，以降低模型學習時受到的干擾。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91a1364",
   "metadata": {},
   "source": [
    "#### import套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a76f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pdb\n",
    "import pprint\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import tqdm.auto as tqdm\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "#from fairseq import utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5176214f",
   "metadata": {},
   "source": [
    "#### 固定random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8c9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 33\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f29a4c",
   "metadata": {},
   "source": [
    "#### data路徑設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22016128",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'zh'\n",
    "\n",
    "data_prefix = f'{data_dir}/raw'\n",
    "test_prefix = f'{data_dir}/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88c0aa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'./data/raw.en'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{data_prefix+'.'+src_lang}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4e1a5",
   "metadata": {},
   "source": [
    "#### 文檔內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "032a0df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you so much, Chris.\n",
      "\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n",
      "\n",
      "I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n",
      "\n",
      "And I say that sincerely, partly because I need that.\n",
      "\n",
      "Put yourselves in my position.\n",
      "\n",
      "非常謝謝你，克里斯。能有這個機會第二度踏上這個演講台\n",
      "\n",
      "真是一大榮幸。我非常感激。\n",
      "\n",
      "這個研討會給我留下了極為深刻的印象，我想感謝大家 對我之前演講的好評。\n",
      "\n",
      "我是由衷的想這麼說，有部份原因是因為 —— 我真的有需要!\n",
      "\n",
      "請你們設身處地為我想一想！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!head {data_prefix+'.'+src_lang} -n 5\n",
    "#!head {data_prefix+'.'+tgt_lang} -n 5\n",
    "\n",
    "with open(f'{data_prefix+\".\"+src_lang}', 'r') as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline())\n",
    "        \n",
    "with open(f'{data_prefix+\".\"+tgt_lang}', 'r',encoding=\"utf-8\") as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e672f",
   "metadata": {},
   "source": [
    "#### cleaning function  \n",
    "* `strQ2B`: 將全形字母與符號轉成半形。  \n",
    "\n",
    "* `clean_s`: 轉半形後，去除文中括號裡的內容，依照中英文去除掉不需要的連接符號、固定符號格式等，最後不論中英文，標點符號兩側連接一個空白。  \n",
    "\n",
    "* `len_s` : 計算句子長度，中文以字為單位，英文以詞為單位。  \n",
    "\n",
    "* `clean_corpus` : Cleaning Function，同時接收兩種語言文本，可設置剃除過長或過短的句子，以及剔除兩種語言句子長度差異過大的資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea2d21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    \"\"\"Full width -> half width\"\"\"\n",
    "    # reference:https://ithelp.ithome.com.tw/articles/10233122\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # Full width space: direct conversion\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # Full width chars (except space) conversion\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)\n",
    "\n",
    "def clean_s(s, lang):\n",
    "    if lang == 'en':\n",
    "        s = strQ2B(s) # Q2B\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace('-', '') # remove '-'\n",
    "        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n",
    "    elif lang == 'zh':\n",
    "        s = strQ2B(s) # Q2B\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace(' ', '')\n",
    "        s = s.replace('—', '')\n",
    "        s = s.replace('“', '\"')\n",
    "        s = s.replace('”', '\"')\n",
    "        s = s.replace('_', '')\n",
    "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n",
    "    s = ' '.join(s.strip().split())\n",
    "    return s\n",
    "\n",
    "def len_s(s, lang):\n",
    "    if lang == 'zh':\n",
    "        return len(s)\n",
    "    return len(s.split())\n",
    "\n",
    "def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n",
    "    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n",
    "        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n",
    "        return\n",
    "    with open(f'{prefix}.{l1}', 'r',encoding=\"utf-8\") as l1_in_f:\n",
    "        with open(f'{prefix}.{l2}', 'r',encoding=\"utf-8\") as l2_in_f:\n",
    "            with open(f'{prefix}.clean.{l1}', 'w',encoding=\"utf-8\") as l1_out_f:\n",
    "                with open(f'{prefix}.clean.{l2}', 'w',encoding=\"utf-8\") as l2_out_f:\n",
    "                    for s1 in l1_in_f:\n",
    "                        s1 = s1.strip()\n",
    "                        s2 = l2_in_f.readline().strip()\n",
    "                        s1 = clean_s(s1, l1)\n",
    "                        s2 = clean_s(s2, l2)\n",
    "                        s1_len = len_s(s1, l1)\n",
    "                        s2_len = len_s(s2, l2)\n",
    "                        if min_len > 0: # remove short sentence\n",
    "                            if s1_len < min_len or s2_len < min_len:\n",
    "                                continue\n",
    "                        if max_len > 0: # remove long sentence\n",
    "                            if s1_len > max_len or s2_len > max_len:\n",
    "                                continue\n",
    "                        if ratio > 0: # remove by ratio of length\n",
    "                            if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n",
    "                                continue\n",
    "                        print(s1, file=l1_out_f)\n",
    "                        print(s2, file=l2_out_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db30c112",
   "metadata": {},
   "source": [
    "####  執行清理  \n",
    "test資料因為需要英翻中，沒有中文(文本內只有句號)，設置數值-1讓其忽略判斷。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88d58803",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus(data_prefix, src_lang, tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14f721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus(test_prefix, src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a32d2",
   "metadata": {},
   "source": [
    "#### valid分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d89113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.01 # 3000~4000 would suffice\n",
    "train_ratio = 1 - valid_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aab46d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(data_dir+f'/train.clean.{src_lang}').exists() \\\n",
    "and Path(data_dir+f'/train.clean.{tgt_lang}').exists() \\\n",
    "and Path(data_dir+f'/valid.clean.{src_lang}').exists() \\\n",
    "and Path(data_dir+f'/valid.clean.{tgt_lang}').exists():\n",
    "    print(f'train/valid splits exists. skipping split.')\n",
    "else:\n",
    "    line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}',encoding=\"utf-8\"))\n",
    "    labels = list(range(line_num))\n",
    "    random.shuffle(labels)\n",
    "    for lang in [src_lang, tgt_lang]:\n",
    "        train_f = open(os.path.join(data_dir, f'train.clean.{lang}'), 'w',encoding=\"utf-8\")\n",
    "        valid_f = open(os.path.join(data_dir, f'valid.clean.{lang}'), 'w',encoding=\"utf-8\")\n",
    "        count = 0\n",
    "        for line in open(f'{data_prefix}.clean.{lang}', 'r',encoding=\"utf-8\"):\n",
    "            if labels[count]/line_num < train_ratio:\n",
    "                train_f.write(line)\n",
    "            else:\n",
    "                valid_f.write(line)\n",
    "            count += 1\n",
    "        train_f.close()\n",
    "        valid_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da4711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
